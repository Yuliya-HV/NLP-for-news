{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP for news "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Identify major breaking news events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Major breaking news events can be identified by noticing that many articles reporting on the same news event have similar content, and are published relatively quickly after the event has happened.\n",
    "\n",
    "For this first part, we ask you to group articles related to the same breaking news event by assigning an eventId to each article. Articles that don’t relate to a major breaking news event should be labelled as “-1”.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import string as string\n",
    "import operator\n",
    "from operator import itemgetter\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import sklearn\n",
    "import time\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "from nltk import word_tokenize as tokenize\n",
    "from nltk import sent_tokenize\n",
    "from nltk.cluster.util import cosine_distance\n",
    "from nltk.corpus import stopwords\n",
    "en_stop = stopwords.words('english')\n",
    "en_stop.append(\"'d\")\n",
    "punctuations = list(string.punctuation)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import gensim.models as gm\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.corpora.textcorpus import TextCorpus\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.similarities import Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read dataset into dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('20190710.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I assume all articles are in English as mentioned in the task even there are articles in Russian appeared in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13022 entries, 0 to 13021\n",
      "Data columns (total 6 columns):\n",
      "ArticleId               13022 non-null object\n",
      "ArticleURL              13022 non-null object\n",
      "ArticleTitle            13022 non-null object\n",
      "ArticleDescription      9594 non-null object\n",
      "ArticlePublishedTime    13022 non-null int64\n",
      "EventId                 0 non-null float64\n",
      "dtypes: float64(1), int64(1), object(4)\n",
      "memory usage: 610.5+ KB\n"
     ]
    }
   ],
   "source": [
    "#look at statistics\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check a lenth of ArticleTitle and ArticleDescription if there are any outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['len_title'] = df.ArticleTitle.apply(lambda x: len(str(x)))\n",
    "df['len_description'] = df.ArticleDescription.apply(lambda x: len(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticlePublishedTime</th>\n",
       "      <th>EventId</th>\n",
       "      <th>len_title</th>\n",
       "      <th>len_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.302200e+04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13022.000000</td>\n",
       "      <td>13022.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.557744e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.471203</td>\n",
       "      <td>261.899247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.670856e+04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.110344</td>\n",
       "      <td>751.004452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.557654e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.557703e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.557749e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>135.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.557781e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>275.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.557826e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>241.000000</td>\n",
       "      <td>26883.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ArticlePublishedTime  EventId     len_title  len_description\n",
       "count          1.302200e+04      0.0  13022.000000     13022.000000\n",
       "mean           1.557744e+09      NaN     69.471203       261.899247\n",
       "std            4.670856e+04      NaN     24.110344       751.004452\n",
       "min            1.557654e+09      NaN      5.000000         3.000000\n",
       "25%            1.557703e+09      NaN     54.000000         3.000000\n",
       "50%            1.557749e+09      NaN     67.000000       135.000000\n",
       "75%            1.557781e+09      NaN     82.000000       275.000000\n",
       "max            1.557826e+09      NaN    241.000000     26883.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 25% of ArticleDescription have 3 chars len (hypothesise NAN after import), it is not informative for the analysis. Remove them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check whether any duplications in ArticleId:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All ActicleId are unique!\n"
     ]
    }
   ],
   "source": [
    "if len(df.ArticleId.unique()) == df.shape[0]:\n",
    "    print('All ActicleId are unique!')\n",
    "else:\n",
    "    print('ArticleId has problems')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform time in readable format for further work. Truncate seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-12 09:32\n"
     ]
    }
   ],
   "source": [
    "df['ArticleTime'] = df.ArticlePublishedTime.apply(lambda x: (pd.to_datetime(x, unit = 's'))) \n",
    "df['ArticleTime'] = df.ArticleTime.apply(lambda x: str(x)[:-3]) \n",
    "print(df['ArticleTime'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate information from Title and Description to have more data about every article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['_Article'] = list(df.ArticleTitle + ' ' + df.ArticleDescription)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove stopwords, punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running time: 0.12 mins\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "\n",
    "_remove = en_stop\n",
    "_remove.append('‘')\n",
    "_remove.append('’')\n",
    "_remove.append('\\'s')\n",
    "\n",
    "df._Article = df._Article.apply(lambda x: tokenize(str(x).translate(str.maketrans('', '', string.punctuation))))\n",
    "df._Article = df._Article.apply(lambda x: [item for item in x if item.lower() not in _remove])\n",
    "\n",
    "print('Running time: {} mins'.format(round((time.time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save a clean string for every article in 'output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output for further work, case normalisation applied\n",
    "df['output'] = df._Article.apply(lambda x: ' '.join(x).lower())\n",
    "\n",
    "#output for working with Named entities, keep original case\n",
    "df['output_ne'] = df._Article.apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the most frequent tokens in the articles, maybe there is something to remove for better performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words in a vocabulary: 47446\n"
     ]
    }
   ],
   "source": [
    "def vocab_counter(df, column_name):\n",
    "    vocab = Counter()\n",
    "    for text in df[column_name]:\n",
    "        for word in str(text).split(' '):\n",
    "            vocab[word] += 1\n",
    "    return vocab\n",
    "\n",
    "print('Total words in a vocabulary: {}'.format(len(vocab_counter(df, 'output'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nan', 3431),\n",
       " ('first', 2032),\n",
       " ('new', 1882),\n",
       " ('said', 1851),\n",
       " ('“', 1836),\n",
       " ('…', 1727),\n",
       " ('”', 1663)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_remove_extra = sorted(vocab.items(), key=lambda x: x[1], reverse=True)[:7]\n",
    "_remove_extra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update text for a every article removing extra uninformative tokens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df._Article = df._Article.apply(lambda x: [item for item in x if item.lower() not in [i[0] for i in _remove_extra]])\n",
    "df.output = df._Article.apply(lambda x: ' '.join(x).lower())\n",
    "df.output_ne = df._Article.apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I do not do stemming and lemmatization as data is not so big and it will not reflect significantly on the result in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution for grouping articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach is a combination of named entity extraction, topic modeling using Latent Dirichlet Allocation (LDA) and KMeans clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform articles into sequence of named entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running time: 3.27 mins\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "\n",
    "#transform articles in Spacy nlp format\n",
    "df['ne_span'] = df.output_ne.apply(lambda x: nlp(x))\n",
    "\n",
    "#create unigrams from bigrams replacing a space with underscore\n",
    "df['ne'] = df.ne_span.apply(lambda x: [ent.text.replace(' ', '_') for ent in x.ents])\n",
    "\n",
    "#transform a new article presentation into a string for a further work convenience\n",
    "df['ne'] = df['ne'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "print('Running time: {} mins'.format(round((time.time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic modeling LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply topic modeling over named entities. I assume that it was 10 major events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1 of max_iter: 10\n",
      "iteration: 2 of max_iter: 10\n",
      "iteration: 3 of max_iter: 10\n",
      "iteration: 4 of max_iter: 10\n",
      "iteration: 5 of max_iter: 10\n",
      "iteration: 6 of max_iter: 10\n",
      "iteration: 7 of max_iter: 10\n",
      "iteration: 8 of max_iter: 10\n",
      "iteration: 9 of max_iter: 10\n",
      "iteration: 10 of max_iter: 10\n"
     ]
    }
   ],
   "source": [
    "#Convert a collection of text documents to a matrix of token counts\n",
    "lda_vectorizer = sklearn.feature_extraction.text.CountVectorizer(min_df = 5, max_df = 0.9)\n",
    "\n",
    "#Learn the vocabulary dictionary and return term-document matrix.\n",
    "lda_data_vectorized = lda_vectorizer.fit_transform(df['ne'])\n",
    "\n",
    "NUM_TOPICS = 10\n",
    "\n",
    "#LDA Model\n",
    "lda = LatentDirichletAllocation(n_components = NUM_TOPICS, max_iter = 10, learning_method = 'online', verbose = True)\n",
    "data_lda = lda.fit_transform(lda_data_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# article - topic matrix\n",
    "lda_output = lda.transform(lda_vectorizer.transform(df.output_ne))\n",
    "# column names\n",
    "topicnames = [\"Topic\" + str(i) for i in range(0, NUM_TOPICS)]\n",
    "# index names\n",
    "docnames = [item for item in df.ArticleId]\n",
    "\n",
    "df_document_topic = pd.DataFrame(np.round(lda_output, 2), columns=topicnames, index=docnames)\n",
    "df_document_topic['_Topic'] = list(df_document_topic.values)\n",
    "\n",
    "#consider the topic is correct if the article got a probability > 0.5\n",
    "df_document_topic['Topic'] = df_document_topic._Topic.apply(lambda x: list(x).index(np.max(x)) if any(x > 0.5) else -1)\n",
    "\n",
    "#add topic information in general dataframe\n",
    "df['Topic'] = np.array(df_document_topic.Topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words for a major events derived by LDA model: \n",
      "\n",
      "Topic 0: \n",
      "[('saturday', 246.49120409487307), ('friday', 235.66770740063112), ('10', 203.79275986202654), ('chinese', 196.6534952298538), ('inquirer_news', 149.8602980706571), ('hong_kong', 148.76605061610135), ('celtic', 96.59537175283356), ('may_13', 79.07611718168809), ('nba', 47.20421689269658), ('swedish', 43.42402057236027)]\n",
      "Topic 1: \n",
      "[('one', 625.0890170326954), ('manchester_united', 157.0151175800864), ('singapore', 135.89034850662645), ('uber', 135.52332333711846), ('chelsea', 133.60424961956974), ('amazon', 122.39093328267725), ('seven', 86.25066688029688), ('ole_gunnar_solskjaer', 79.60561145336007), ('eden_hazard', 72.3765045052068), ('barcelona', 69.65278404759039)]\n",
      "Topic 2: \n",
      "[('us', 792.3198336533801), ('china', 412.9107310094856), ('three', 410.29225417568836), ('tuesday', 287.4857919807417), ('trump', 144.5633379977283), ('summer', 141.75470477196524), ('donald_trump', 102.1803067053905), ('french', 92.00694737083694), ('washington', 88.42328006183786), ('american', 85.24375264558921)]\n",
      "Topic 3: \n",
      "[('second', 412.6478487812956), ('thursday', 101.44610594677965), ('annual', 86.49223655192394), ('11', 82.04602966836613), ('2020', 72.11187332127638), ('afternoon', 65.08767938196655), ('hollywood', 62.422899279503085), ('doris_day', 58.38120748189226), ('europe', 56.47164669191504), ('spanish', 54.37612912411212)]\n",
      "Topic 4: \n",
      "[('premier_league', 352.23237726800653), ('manchester_city', 213.25320832047169), ('five', 204.78799489334355), ('brighton', 116.9556856327142), ('european', 100.14339204104938), ('sunday', 94.17250589048783), ('liverpool', 92.29246824250488), ('iran', 68.66984046507791), ('man_city', 64.76403294105636), ('97', 60.95812105346451)]\n",
      "Topic 5: \n",
      "[('four', 290.84939713763305), ('today', 290.745622153385), ('2019', 280.94165114867553), ('premier_league', 141.67155601098202), ('champions_league', 98.0959499343855), ('fifth', 80.79542475908934), ('fourth', 78.28347080018968), ('next_year', 69.50240212725805), ('season', 60.4243652698284), ('tottenham', 55.56534407460085)]\n",
      "Topic 6: \n",
      "[('monday', 792.265470635308), ('sunday', 367.5038961651292), ('six', 151.02628895129905), ('morning', 102.63600282028636), ('eight', 91.77601234996926), ('yesterday', 89.40997394030303), ('japan', 77.59142546364988), ('facebook', 77.48452905756888), ('nine', 70.8926753760206), ('30', 68.46063987876477)]\n",
      "Topic 7: \n",
      "[('third', 212.32081136847117), ('one', 199.05045511087587), ('dallas', 124.74007324721167), ('week', 109.00032963770275), ('instagram', 105.09020345954116), ('united_states', 72.54441066611273), ('sixth', 72.47577666516499), ('philippines', 58.07583257803216), ('mavericks', 57.52442818629806), ('continued', 53.607660712686645)]\n",
      "Topic 8: \n",
      "[('uk', 173.24178981271248), ('london', 131.20155061242892), ('12', 122.42897239811617), ('google', 107.10320028356226), ('british', 95.83338106247975), ('year', 79.89322261947623), ('britain', 76.80496137463835), ('wednesday', 76.55331511320182), ('years', 76.3156517227714), ('may', 76.22789658454394)]\n",
      "Topic 9: \n",
      "[('two', 826.7504945235119), ('game_thrones', 198.5196942626395), ('20', 166.9006921689113), ('apple', 159.42614057370187), ('last_week', 146.39172077491193), ('last_year', 143.70041528688014), ('night', 82.80359062854038), ('microsoft', 78.87857672086535), ('50', 57.04240614835315), ('100', 55.768909907543744)]\n"
     ]
    }
   ],
   "source": [
    "#function for printing key words for detected topic\n",
    "\n",
    "def selected_topic(model, vectorizer, top_n = 10):\n",
    "    for i, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d: \"%(i))\n",
    "        print([(lda_vectorizer.get_feature_names()[i], topic[i])\n",
    "              for i in topic.argsort()[:-top_n - 1:-1]])\n",
    "\n",
    "print(\"Top words for a major events derived by LDA model: \")\n",
    "print('')\n",
    "selected_topic(lda, lda_vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out a number of articles per event. I consider an article as a valid if it probability is more than 50% that the article belongs to the particular topic (as LDA adds all documents in all topics varying just their probabilities). Articles having probabilities lower than 0.5 to any topis are considered as not relevant and labeled as -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EventId</th>\n",
       "      <th>Number of Articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>9559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    EventId  Number of Articles\n",
       "0        -1                9559\n",
       "1         8                 692\n",
       "2         2                 513\n",
       "3         7                 417\n",
       "4         5                 392\n",
       "5         1                 337\n",
       "6         9                 302\n",
       "7         6                 292\n",
       "8         3                 222\n",
       "9         0                 162\n",
       "10        4                 134"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topic_distribution = df_document_topic.Topic.value_counts().reset_index(name=\"Num Documents\")\n",
    "df_topic_distribution.columns = ['EventId', 'Number of Articles']\n",
    "df_topic_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The articles are already grouped in a sensible manner, see the result for instance, for a Topic (event) 4 below. But it still needs additional grouping within topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleTitle</th>\n",
       "      <th>ArticleDescription</th>\n",
       "      <th>ArticleTime</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Man Utd vs Cardiff TV channel: What TV channel...</td>\n",
       "      <td>MANCHESTER UNITED end their Premier League cam...</td>\n",
       "      <td>2019-05-12 09:44</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chelsea 'are only team to show interest in Bar...</td>\n",
       "      <td>Coutinho, who has struggled to impress for Bar...</td>\n",
       "      <td>2019-05-12 09:48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How Amazon dumps millions of new items it can’...</td>\n",
       "      <td>AMAZON dumps and destroys millions of brand-ne...</td>\n",
       "      <td>2019-05-12 10:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Man Utd duo Paul Pogba and Alexis Sanchez at h...</td>\n",
       "      <td>MANCHESTER UNITED stars are jealous of Alexis ...</td>\n",
       "      <td>2019-05-12 10:18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Silver King: il wrestler messicano muore sul ring</td>\n",
       "      <td>Cesar Cuauhtemoc Gonzalez Barron, questo il su...</td>\n",
       "      <td>2019-05-12 10:20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Uber’s rocky road to global powerhouse</td>\n",
       "      <td>Uber, set to make its stock market debut in on...</td>\n",
       "      <td>2019-05-12 10:27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Experience Kallang's rich history in new 3km w...</td>\n",
       "      <td>SINGAPORE - Take a 3km walk on a trail that wi...</td>\n",
       "      <td>2019-05-12 10:40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Man Utd want one transfer deal because of Chel...</td>\n",
       "      <td>MANCHESTER UNITED want to sign Everton’s Idris...</td>\n",
       "      <td>2019-05-12 10:50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7 nabbed for alleged vote-buying in Iloilo</td>\n",
       "      <td>Seven persons were arrested in Iloilo amid rep...</td>\n",
       "      <td>2019-05-12 10:52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ciara can’t get enough of high-top sneakers</td>\n",
       "      <td>Ciara loves the way high-top sneakers can be p...</td>\n",
       "      <td>2019-05-12 10:59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Russia and far right spreading disinformation ...</td>\n",
       "      <td>The goal here is bigger than any one election....</td>\n",
       "      <td>2019-05-12 11:13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Refugee Afghan entrepreneurs building successf...</td>\n",
       "      <td>When Afghan businessman Haji Yakup Burhan fled...</td>\n",
       "      <td>2019-05-12 11:34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Man Utd eye £40m transfer bid for Everton midf...</td>\n",
       "      <td>MANCHESTER UNITED are lining up a summer swoop...</td>\n",
       "      <td>2019-05-12 11:52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>In 'Australia's salad bowl', Pauline Hanson is...</td>\n",
       "      <td>Despite a rocky federal election campaign, sup...</td>\n",
       "      <td>2019-05-12 11:56</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>What's a dry sump and how does it work? Steph ...</td>\n",
       "      <td>One of the smartest racecar builders around br...</td>\n",
       "      <td>2019-05-12 12:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Brian Walden dead aged 86: Legendary TV interv...</td>\n",
       "      <td>Brian represented the constituency of Birmingh...</td>\n",
       "      <td>2019-05-12 12:04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Arsenal blow as Barcelona close in on transfer...</td>\n",
       "      <td>ANY slim chances Arsenal had of signing Ajax p...</td>\n",
       "      <td>2019-05-12 12:11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>En garde! France embraces the lightsaber — as ...</td>\n",
       "      <td>It has for decades been the dream of the young...</td>\n",
       "      <td>2019-05-12 12:13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Brian Walden dead – legendary TV interviewer d...</td>\n",
       "      <td>LEGENDARY TV interviewer Brian Walden has died...</td>\n",
       "      <td>2019-05-12 12:13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Real Madrid team news: Predicted 4-3-3 line up...</td>\n",
       "      <td>REAL MADRID have a number of key players missi...</td>\n",
       "      <td>2019-05-12 12:15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         ArticleTitle  \\\n",
       "0   Man Utd vs Cardiff TV channel: What TV channel...   \n",
       "1   Chelsea 'are only team to show interest in Bar...   \n",
       "2   How Amazon dumps millions of new items it can’...   \n",
       "3   Man Utd duo Paul Pogba and Alexis Sanchez at h...   \n",
       "4   Silver King: il wrestler messicano muore sul ring   \n",
       "5              Uber’s rocky road to global powerhouse   \n",
       "6   Experience Kallang's rich history in new 3km w...   \n",
       "7   Man Utd want one transfer deal because of Chel...   \n",
       "8          7 nabbed for alleged vote-buying in Iloilo   \n",
       "9         Ciara can’t get enough of high-top sneakers   \n",
       "10  Russia and far right spreading disinformation ...   \n",
       "11  Refugee Afghan entrepreneurs building successf...   \n",
       "12  Man Utd eye £40m transfer bid for Everton midf...   \n",
       "13  In 'Australia's salad bowl', Pauline Hanson is...   \n",
       "14  What's a dry sump and how does it work? Steph ...   \n",
       "15  Brian Walden dead aged 86: Legendary TV interv...   \n",
       "16  Arsenal blow as Barcelona close in on transfer...   \n",
       "17  En garde! France embraces the lightsaber — as ...   \n",
       "18  Brian Walden dead – legendary TV interviewer d...   \n",
       "19  Real Madrid team news: Predicted 4-3-3 line up...   \n",
       "\n",
       "                                   ArticleDescription       ArticleTime  Topic  \n",
       "0   MANCHESTER UNITED end their Premier League cam...  2019-05-12 09:44      1  \n",
       "1   Coutinho, who has struggled to impress for Bar...  2019-05-12 09:48      1  \n",
       "2   AMAZON dumps and destroys millions of brand-ne...  2019-05-12 10:00      1  \n",
       "3   MANCHESTER UNITED stars are jealous of Alexis ...  2019-05-12 10:18      1  \n",
       "4   Cesar Cuauhtemoc Gonzalez Barron, questo il su...  2019-05-12 10:20      1  \n",
       "5   Uber, set to make its stock market debut in on...  2019-05-12 10:27      1  \n",
       "6   SINGAPORE - Take a 3km walk on a trail that wi...  2019-05-12 10:40      1  \n",
       "7   MANCHESTER UNITED want to sign Everton’s Idris...  2019-05-12 10:50      1  \n",
       "8   Seven persons were arrested in Iloilo amid rep...  2019-05-12 10:52      1  \n",
       "9   Ciara loves the way high-top sneakers can be p...  2019-05-12 10:59      1  \n",
       "10  The goal here is bigger than any one election....  2019-05-12 11:13      1  \n",
       "11  When Afghan businessman Haji Yakup Burhan fled...  2019-05-12 11:34      1  \n",
       "12  MANCHESTER UNITED are lining up a summer swoop...  2019-05-12 11:52      1  \n",
       "13  Despite a rocky federal election campaign, sup...  2019-05-12 11:56      1  \n",
       "14  One of the smartest racecar builders around br...  2019-05-12 12:00      1  \n",
       "15  Brian represented the constituency of Birmingh...  2019-05-12 12:04      1  \n",
       "16  ANY slim chances Arsenal had of signing Ajax p...  2019-05-12 12:11      1  \n",
       "17  It has for decades been the dream of the young...  2019-05-12 12:13      1  \n",
       "18  LEGENDARY TV interviewer Brian Walden has died...  2019-05-12 12:13      1  \n",
       "19  REAL MADRID have a number of key players missi...  2019-05-12 12:15      1  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.Topic == 1)].groupby('Topic')[['ArticleTitle', 'ArticleDescription', 'ArticleTime', 'Topic']].head(20).sort_values(by = 'ArticleTime', ascending = True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As few events can happen at the same moment around the world so I cannot extract articles just by timings (calculating cosine similarity is not too reliable method also in this case). \n",
    "\n",
    "I will cluster each of the selection of article by topic (result above) and look at the output.\n",
    "\n",
    "I omit all articles labeled as -1 for clustering (means they are not involved in any topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3463, 4)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cluster = df[(df.Topic > -1)][['ArticleId', 'output_ne', 'ArticleTime', 'Topic']].sort_values(by = 'Topic', ascending = True).reset_index(drop=True)\n",
    "df_cluster.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMeans clustering for every topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a column to save clusters'numbers\n",
    "df_cluster['Topic_KMeans'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume there are 5 events within every major topic discovered above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 10\n",
    "\n",
    "model = KMeans(n_clusters = n_clusters, init='k-means++', max_iter=100, n_init=10)\n",
    "\n",
    "#function to extract clusters within a topic\n",
    "def get_cluster_topic(model, df):\n",
    "    # save all article in a list\n",
    "    articles = list(*[df[c].values.tolist() for c in ['output_ne']])\n",
    "    kmeans_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    X = kmeans_vectorizer.fit_transform(articles)        \n",
    "    model.fit(X)\n",
    "    return model.labels_\n",
    "\n",
    "_clustering = []\n",
    "\n",
    "#run over all 10 topic\n",
    "for i in range(0, 10):\n",
    "    clustering = get_cluster_topic(model, df_cluster[df_cluster.Topic == i])\n",
    "    #print(clustering)\n",
    "    _clustering.append(clustering)\n",
    "    \n",
    "#update dataframe with cluster numbers for every article\n",
    "df_cluster.Topic_KMeans = np.concatenate([item for item in _clustering])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess the result of clustering articles by topics. See a selection of articles grouped in one particular event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleId</th>\n",
       "      <th>output_ne</th>\n",
       "      <th>ArticleTime</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Topic_KMeans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5cd7ec5f7ddacd3b2b3b5462</td>\n",
       "      <td>Chelsea team show interest Barcelona flop Phil...</td>\n",
       "      <td>2019-05-12 09:48</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5cd8375d7ddacd3b2b3b6681</td>\n",
       "      <td>Lionel Messi Chelsea star Eden Hazard Messi to...</td>\n",
       "      <td>2019-05-12 14:06</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5cd8522b8e662d1e4435e9d3</td>\n",
       "      <td>Fans BEG Eden Hazard stay Chelsea home banner ...</td>\n",
       "      <td>2019-05-12 16:35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5cd863b47ddacd3b2b3b7211</td>\n",
       "      <td>Chelsea want Barcelona star replace Eden Hazar...</td>\n",
       "      <td>2019-05-12 18:23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5cd867197ddacd3b2b3b72ab</td>\n",
       "      <td>Hazard future still uncertain says Chelsea bos...</td>\n",
       "      <td>2019-05-12 18:32</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5cd8a0cb8e662d1e4435f893</td>\n",
       "      <td>Eden Hazard Chelsea must respect forwards deci...</td>\n",
       "      <td>2019-05-12 19:37</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5cd892708e662d1e4435f6c6</td>\n",
       "      <td>Hazard drops biggest hint yet told Chelsea Rea...</td>\n",
       "      <td>2019-05-12 21:30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5cd8909a8e662d1e4435f663</td>\n",
       "      <td>Eden Hazard drops Chelsea transfer bombshell m...</td>\n",
       "      <td>2019-05-12 21:30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5cd8911b8e662d1e4435f67e</td>\n",
       "      <td>made decision Eden Hazard reveals told Chelsea...</td>\n",
       "      <td>2019-05-12 21:30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5cd8935c7ddacd3b2b3b7a37</td>\n",
       "      <td>Eden Hazard drops biggest transfer hint yet Ch...</td>\n",
       "      <td>2019-05-12 21:30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5cd8a67b8e662d1e4435f922</td>\n",
       "      <td>Football gossip Hazard Coutinho Pogba Rice Lac...</td>\n",
       "      <td>2019-05-12 23:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5cd8c7728e662d1e4435febe</td>\n",
       "      <td>Chelsea manager drops update Eden Hazards futu...</td>\n",
       "      <td>2019-05-13 01:28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5cd8e5358e662d1e443604f8</td>\n",
       "      <td>Belgian stars future still uncertain says Chel...</td>\n",
       "      <td>2019-05-13 03:09</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5cd901568e662d1e44360c63</td>\n",
       "      <td>Eden Hazard Chelsea fans say thing Real Madrid...</td>\n",
       "      <td>2019-05-13 05:09</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5cd9108b8e662d1e44361056</td>\n",
       "      <td>Eden Hazard Chelsea star drops huge hint Real ...</td>\n",
       "      <td>2019-05-13 06:36</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5cd9128c7ddacd3b2b3b9225</td>\n",
       "      <td>Eden Hazard talking Real Madrid players transf...</td>\n",
       "      <td>2019-05-13 06:44</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5cd926ed8e662d1e443617a1</td>\n",
       "      <td>Chelsea star Eden Hazard talking THREE Real Ma...</td>\n",
       "      <td>2019-05-13 07:48</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5cd9266f8e662d1e44361773</td>\n",
       "      <td>Transfer news gossip column Paul Pogba told le...</td>\n",
       "      <td>2019-05-13 08:08</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5cd931fc8e662d1e44361b9f</td>\n",
       "      <td>Hazard says Chelsea know future made decision ...</td>\n",
       "      <td>2019-05-13 08:21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5cd94f1a7ddacd3b2b3bae99</td>\n",
       "      <td>Chelsea star Eden Hazard seeks move prove hes ...</td>\n",
       "      <td>2019-05-13 11:01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5cd976bd7ddacd712a94ece8</td>\n",
       "      <td>Real Madrid set officially announce Eden Hazar...</td>\n",
       "      <td>2019-05-13 13:43</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5cd9791a8e662d1d7e41a6f1</td>\n",
       "      <td>Real Madrid officially announce £86m signing E...</td>\n",
       "      <td>2019-05-13 14:02</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5cd97c6f8e662d1d7e41a872</td>\n",
       "      <td>Eden Hazard transfer day Real Madrid announce ...</td>\n",
       "      <td>2019-05-13 14:12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5cd9895a8e662d1d7e41ad87</td>\n",
       "      <td>Eden Hazard Real Madrid Chelsea transfer plan ...</td>\n",
       "      <td>2019-05-13 14:32</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5cd988e77ddacd712a94f4bf</td>\n",
       "      <td>Eden Hazard sends parting message Chelsea ahea...</td>\n",
       "      <td>2019-05-13 14:42</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5cd99bf47ddacd6310df6c00</td>\n",
       "      <td>Pulisic names top player looking forward playi...</td>\n",
       "      <td>2019-05-13 16:26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5cd9a66a7ddacd6310df6f79</td>\n",
       "      <td>Barcelona expecting Chelsea make Philippe Cout...</td>\n",
       "      <td>2019-05-13 17:05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5cd9a9c17ddacd6310df703f</td>\n",
       "      <td>Eden Hazard sends Maurizio Sarri message Chels...</td>\n",
       "      <td>2019-05-13 17:24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5cd9b7b38e662d2daa78d586</td>\n",
       "      <td>clue Eden Hazard leave Chelsea Real Madrid sum...</td>\n",
       "      <td>2019-05-13 17:33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5cd9b0678e662d2daa78d365</td>\n",
       "      <td>Frank Lampard believes Chelsea able replace Ed...</td>\n",
       "      <td>2019-05-13 17:57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>5cd9b7b58e662d2daa78d588</td>\n",
       "      <td>Chelsea transfer news Barcelona expect Philipp...</td>\n",
       "      <td>2019-05-13 18:08</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>5cd9b3e17ddacd6310df72f7</td>\n",
       "      <td>Real Madrid target Eden Hazard admits Europa L...</td>\n",
       "      <td>2019-05-13 18:12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>5cd9e2857ddacd6310df7d76</td>\n",
       "      <td>Real Madrid confident signing Chelsea star Ede...</td>\n",
       "      <td>2019-05-13 21:30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>5cd9e29b7ddacd6310df7d86</td>\n",
       "      <td>Eden Hazard EXCLUSIVE Chelsea ace frustrated R...</td>\n",
       "      <td>2019-05-13 21:30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>5cd9e3188e662d2daa78e008</td>\n",
       "      <td>Chelsea grant Eden Hazard dream move Real Madr...</td>\n",
       "      <td>2019-05-13 21:31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>5cda7bbd8e662d2daa7905f1</td>\n",
       "      <td>Chelsea must respect Eden Hazards decision ami...</td>\n",
       "      <td>2019-05-14 08:23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>5cda890b8e662d2daa790dab</td>\n",
       "      <td>Eden Hazard transfer Real Madrid balance Chels...</td>\n",
       "      <td>2019-05-14 09:10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ArticleId  \\\n",
       "0   5cd7ec5f7ddacd3b2b3b5462   \n",
       "1   5cd8375d7ddacd3b2b3b6681   \n",
       "2   5cd8522b8e662d1e4435e9d3   \n",
       "3   5cd863b47ddacd3b2b3b7211   \n",
       "4   5cd867197ddacd3b2b3b72ab   \n",
       "5   5cd8a0cb8e662d1e4435f893   \n",
       "6   5cd892708e662d1e4435f6c6   \n",
       "7   5cd8909a8e662d1e4435f663   \n",
       "8   5cd8911b8e662d1e4435f67e   \n",
       "9   5cd8935c7ddacd3b2b3b7a37   \n",
       "10  5cd8a67b8e662d1e4435f922   \n",
       "11  5cd8c7728e662d1e4435febe   \n",
       "12  5cd8e5358e662d1e443604f8   \n",
       "13  5cd901568e662d1e44360c63   \n",
       "14  5cd9108b8e662d1e44361056   \n",
       "15  5cd9128c7ddacd3b2b3b9225   \n",
       "16  5cd926ed8e662d1e443617a1   \n",
       "17  5cd9266f8e662d1e44361773   \n",
       "18  5cd931fc8e662d1e44361b9f   \n",
       "19  5cd94f1a7ddacd3b2b3bae99   \n",
       "20  5cd976bd7ddacd712a94ece8   \n",
       "21  5cd9791a8e662d1d7e41a6f1   \n",
       "22  5cd97c6f8e662d1d7e41a872   \n",
       "23  5cd9895a8e662d1d7e41ad87   \n",
       "24  5cd988e77ddacd712a94f4bf   \n",
       "25  5cd99bf47ddacd6310df6c00   \n",
       "26  5cd9a66a7ddacd6310df6f79   \n",
       "27  5cd9a9c17ddacd6310df703f   \n",
       "28  5cd9b7b38e662d2daa78d586   \n",
       "29  5cd9b0678e662d2daa78d365   \n",
       "30  5cd9b7b58e662d2daa78d588   \n",
       "31  5cd9b3e17ddacd6310df72f7   \n",
       "32  5cd9e2857ddacd6310df7d76   \n",
       "33  5cd9e29b7ddacd6310df7d86   \n",
       "34  5cd9e3188e662d2daa78e008   \n",
       "35  5cda7bbd8e662d2daa7905f1   \n",
       "36  5cda890b8e662d2daa790dab   \n",
       "\n",
       "                                            output_ne       ArticleTime  \\\n",
       "0   Chelsea team show interest Barcelona flop Phil...  2019-05-12 09:48   \n",
       "1   Lionel Messi Chelsea star Eden Hazard Messi to...  2019-05-12 14:06   \n",
       "2   Fans BEG Eden Hazard stay Chelsea home banner ...  2019-05-12 16:35   \n",
       "3   Chelsea want Barcelona star replace Eden Hazar...  2019-05-12 18:23   \n",
       "4   Hazard future still uncertain says Chelsea bos...  2019-05-12 18:32   \n",
       "5   Eden Hazard Chelsea must respect forwards deci...  2019-05-12 19:37   \n",
       "6   Hazard drops biggest hint yet told Chelsea Rea...  2019-05-12 21:30   \n",
       "7   Eden Hazard drops Chelsea transfer bombshell m...  2019-05-12 21:30   \n",
       "8   made decision Eden Hazard reveals told Chelsea...  2019-05-12 21:30   \n",
       "9   Eden Hazard drops biggest transfer hint yet Ch...  2019-05-12 21:30   \n",
       "10  Football gossip Hazard Coutinho Pogba Rice Lac...  2019-05-12 23:00   \n",
       "11  Chelsea manager drops update Eden Hazards futu...  2019-05-13 01:28   \n",
       "12  Belgian stars future still uncertain says Chel...  2019-05-13 03:09   \n",
       "13  Eden Hazard Chelsea fans say thing Real Madrid...  2019-05-13 05:09   \n",
       "14  Eden Hazard Chelsea star drops huge hint Real ...  2019-05-13 06:36   \n",
       "15  Eden Hazard talking Real Madrid players transf...  2019-05-13 06:44   \n",
       "16  Chelsea star Eden Hazard talking THREE Real Ma...  2019-05-13 07:48   \n",
       "17  Transfer news gossip column Paul Pogba told le...  2019-05-13 08:08   \n",
       "18  Hazard says Chelsea know future made decision ...  2019-05-13 08:21   \n",
       "19  Chelsea star Eden Hazard seeks move prove hes ...  2019-05-13 11:01   \n",
       "20  Real Madrid set officially announce Eden Hazar...  2019-05-13 13:43   \n",
       "21  Real Madrid officially announce £86m signing E...  2019-05-13 14:02   \n",
       "22  Eden Hazard transfer day Real Madrid announce ...  2019-05-13 14:12   \n",
       "23  Eden Hazard Real Madrid Chelsea transfer plan ...  2019-05-13 14:32   \n",
       "24  Eden Hazard sends parting message Chelsea ahea...  2019-05-13 14:42   \n",
       "25  Pulisic names top player looking forward playi...  2019-05-13 16:26   \n",
       "26  Barcelona expecting Chelsea make Philippe Cout...  2019-05-13 17:05   \n",
       "27  Eden Hazard sends Maurizio Sarri message Chels...  2019-05-13 17:24   \n",
       "28  clue Eden Hazard leave Chelsea Real Madrid sum...  2019-05-13 17:33   \n",
       "29  Frank Lampard believes Chelsea able replace Ed...  2019-05-13 17:57   \n",
       "30  Chelsea transfer news Barcelona expect Philipp...  2019-05-13 18:08   \n",
       "31  Real Madrid target Eden Hazard admits Europa L...  2019-05-13 18:12   \n",
       "32  Real Madrid confident signing Chelsea star Ede...  2019-05-13 21:30   \n",
       "33  Eden Hazard EXCLUSIVE Chelsea ace frustrated R...  2019-05-13 21:30   \n",
       "34  Chelsea grant Eden Hazard dream move Real Madr...  2019-05-13 21:31   \n",
       "35  Chelsea must respect Eden Hazards decision ami...  2019-05-14 08:23   \n",
       "36  Eden Hazard transfer Real Madrid balance Chels...  2019-05-14 09:10   \n",
       "\n",
       "    Topic  Topic_KMeans  \n",
       "0       1             1  \n",
       "1       1             1  \n",
       "2       1             1  \n",
       "3       1             1  \n",
       "4       1             1  \n",
       "5       1             1  \n",
       "6       1             1  \n",
       "7       1             1  \n",
       "8       1             1  \n",
       "9       1             1  \n",
       "10      1             1  \n",
       "11      1             1  \n",
       "12      1             1  \n",
       "13      1             1  \n",
       "14      1             1  \n",
       "15      1             1  \n",
       "16      1             1  \n",
       "17      1             1  \n",
       "18      1             1  \n",
       "19      1             1  \n",
       "20      1             1  \n",
       "21      1             1  \n",
       "22      1             1  \n",
       "23      1             1  \n",
       "24      1             1  \n",
       "25      1             1  \n",
       "26      1             1  \n",
       "27      1             1  \n",
       "28      1             1  \n",
       "29      1             1  \n",
       "30      1             1  \n",
       "31      1             1  \n",
       "32      1             1  \n",
       "33      1             1  \n",
       "34      1             1  \n",
       "35      1             1  \n",
       "36      1             1  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " df_cluster[(df_cluster.Topic == 1) & (df_cluster.Topic_KMeans == 1)].sort_values(by = 'ArticleTime', ascending = True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen from the output above that I grouped articles by an event they describe. All articles above about Eden Hazard and Real Madrid grouped in one cluster, I can say this is one event. There is maybe 1-2 articles are not strongly about the event, this is kind of error of my approach. To exclude that small error it is possible simply calculate *cosine similarity between articles within one cluster* (this data is not sparse so the performance will be accurate enough) to be sure with a high degree the article is exactly describes the event. \n",
    "I will not do that simple operation here due to luck of time.\n",
    "\n",
    "I have not involved time publishing parameter as you noticed. Maybe using another approach it will be useful to use time as a main parameter for a decision about article relevancy to event. \n",
    "\n",
    "Also the dataset contains articles for a short period. If I had articles for a larger period I would additionally filter my result above by selecting articles, for example, during 24 hours after first its appearance. But maybe in that case I will be able to put the article into breaking news category. I am not a media specialist and not sure how much time the article can be considered as a 'hot' (24 hours picked as an example). Although the example of extraction above shows they publish articles even over 24 hours boundary, it should be included or not I do not know ). Need media professional judgment.\n",
    "\n",
    "In conclusion, I grouped the articles as asked in the question, identified 99 events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill EventId column\n",
    "df_cluster['EventId'] = pd.to_numeric(df_cluster.Topic.map(str) + df_cluster.Topic_KMeans.map(str))\n",
    "df.drop('EventId', axis = 1, inplace = True)\n",
    "df_q1 = pd.merge(df, df_cluster[['ArticleId', 'EventId']], on = 'ArticleId', how = 'left')\n",
    "df_q1.EventId.fillna(-1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional approaches, less quality result as for now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have tried clear KMeans and LDA but the performance is not so impressive as from the solution above. Maybe need more time to go a bit deeper into those algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMeans clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all article in a list\n",
    "documents = list(*[df[c].values.tolist() for c in ['output_ne']])\n",
    "ids = list(*[df[c].values.tolist() for c in ['ArticleId']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = kmeans_vectorizer.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume there are 10 events happened during two days. Define number of clusters equals 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=100,\n",
       "    n_clusters=10, n_init=10, n_jobs=None, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_clusters = 10\n",
    "model = KMeans(n_clusters = n_clusters, init='k-means++', max_iter=100, n_init=10)\n",
    "model.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add number of relevant cluster to the dataframe with articles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['KMeans'] = model.labels_.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amount of articles per cluster (event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    12293\n",
       "8      590\n",
       "4       84\n",
       "5       19\n",
       "7       13\n",
       "2       10\n",
       "6        7\n",
       "3        3\n",
       "9        2\n",
       "0        1\n",
       "Name: KMeans, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.KMeans.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution among clusters looks weird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "Cluster 0: minnesota eastbound 36 traffic closed 694 36hadley detour sewer installation \n",
      "Cluster 1: post appeared monday day game says season police years time \n",
      "Cluster 2: charles st avenue kane girl quartuccio geneva driver scene fled \n",
      "Cluster 3: progeny business daughter ties lucy enters joined industry compere chows \n",
      "Cluster 4: bafta awards tv 2019 carpet red jodie ant eve comer \n",
      "Cluster 5: sri lanka mosques easter muslimowned curfew bombings social media colombo \n",
      "Cluster 6: brotherinlaw best allegations world sgx confirmed connections customer chief ceos \n",
      "Cluster 7: leeds derby playoff lampard marcelo bielsa semifinal championship leg frank \n",
      "Cluster 8: league premier liverpool city manchester title season man final champions \n",
      "Cluster 9: protesters omar albashir ousted sudan killing charged president involvement prosecutors \n"
     ]
    }
   ],
   "source": [
    "clusters_dic = {}\n",
    "\n",
    "print(\"Top terms per cluster:\")\n",
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = kmeans_vectorizer.get_feature_names()\n",
    "for i in range(n_clusters):\n",
    "    words = ''\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        #print (' %s' % terms[ind])\n",
    "        words += terms[ind]+ ' '\n",
    "    clusters_dic[i] = words\n",
    "    print (\"Cluster %d:\" % i, words)\n",
    "    #print() #add whitespace\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: I refuse the idea to use KMean clustering only for this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling. LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsicity:  0.15175036818158819 %\n"
     ]
    }
   ],
   "source": [
    "# Materialize the sparse data\n",
    "data_dense = lda_data_vectorized.todense()\n",
    "\n",
    "# Compute Sparsicity = Percentage of Non-Zero cells\n",
    "print(\"Sparsicity: \", ((data_dense > 0).sum()/data_dense.size)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA Model\n",
    "lda_model = LatentDirichletAllocation(n_topics=20,               # Number of topics\n",
    "                                      max_iter=10,               # Max learning iterations\n",
    "                                      learning_method='online',   \n",
    "                                      random_state=100,          # Random state\n",
    "                                      batch_size=128,            # n docs in each learning iter\n",
    "                                      evaluate_every = -1,       # compute perplexity every n iters, default: Don't\n",
    "                                      n_jobs = -1,               # Use all available CPUs\n",
    "                                     )\n",
    "lda_output = lda_model.fit_transform(lda_data_vectorized)\n",
    "\n",
    "print(lda_model)  # Model attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Search Param\n",
    "search_params = {'n_components': [10, 20, 100], 'learning_decay': [.7]}\n",
    "\n",
    "# Init the Model\n",
    "lda = LatentDirichletAllocation()\n",
    "\n",
    "# Init Grid Search Class\n",
    "model = GridSearchCV(lda, param_grid=search_params)\n",
    "\n",
    "# Do the Grid Search\n",
    "model.fit(lda_data_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model's Params:  {'learning_decay': 0.7, 'n_components': 10}\n",
      "Best Log Likelihood Score:  -82874.59014212845\n",
      "Model Perplexity:  550.1253864555185\n"
     ]
    }
   ],
   "source": [
    "# Best Model\n",
    "best_lda_model = model.best_estimator_\n",
    "\n",
    "# Model Parameters\n",
    "print(\"Best Model's Params: \", model.best_params_)\n",
    "\n",
    "# Log Likelihood Score\n",
    "print(\"Best Log Likelihood Score: \", model.best_score_)\n",
    "\n",
    "# Perplexity\n",
    "print(\"Model Perplexity: \", best_lda_model.perplexity(lda_data_vectorized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow0_col0 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow0_col1 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow0_col2 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow0_col3 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow0_col4 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow0_col5 {\n",
       "            color:  red;\n",
       "            font-weight:  700;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow0_col6 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow0_col7 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow0_col8 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow0_col9 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow0_col10 {\n",
       "            color:  red;\n",
       "            font-weight:  700;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow1_col0 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow1_col1 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow1_col2 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow1_col3 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow1_col4 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow1_col5 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow1_col6 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow1_col7 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow1_col8 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow1_col9 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow1_col10 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow2_col0 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow2_col1 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow2_col2 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow2_col3 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow2_col4 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow2_col5 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow2_col6 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow2_col7 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow2_col8 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow2_col9 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow2_col10 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow3_col0 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow3_col1 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow3_col2 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow3_col3 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow3_col4 {\n",
       "            color:  red;\n",
       "            font-weight:  700;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow3_col5 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow3_col6 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow3_col7 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow3_col8 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow3_col9 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow3_col10 {\n",
       "            color:  red;\n",
       "            font-weight:  700;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow4_col0 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow4_col1 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow4_col2 {\n",
       "            color:  red;\n",
       "            font-weight:  700;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow4_col3 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow4_col4 {\n",
       "            color:  red;\n",
       "            font-weight:  700;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow4_col5 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow4_col6 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow4_col7 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow4_col8 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow4_col9 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow4_col10 {\n",
       "            color:  red;\n",
       "            font-weight:  700;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow5_col0 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow5_col1 {\n",
       "            color:  red;\n",
       "            font-weight:  700;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow5_col2 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow5_col3 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow5_col4 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow5_col5 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow5_col6 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow5_col7 {\n",
       "            color:  red;\n",
       "            font-weight:  700;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow5_col8 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow5_col9 {\n",
       "            color:  red;\n",
       "            font-weight:  700;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow5_col10 {\n",
       "            color:  red;\n",
       "            font-weight:  700;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow6_col0 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow6_col1 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow6_col2 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow6_col3 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow6_col4 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow6_col5 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow6_col6 {\n",
       "            color:  red;\n",
       "            font-weight:  700;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow6_col7 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow6_col8 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow6_col9 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow6_col10 {\n",
       "            color:  red;\n",
       "            font-weight:  700;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow7_col0 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow7_col1 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow7_col2 {\n",
       "            color:  red;\n",
       "            font-weight:  700;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow7_col3 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow7_col4 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow7_col5 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow7_col6 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow7_col7 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow7_col8 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow7_col9 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow7_col10 {\n",
       "            color:  red;\n",
       "            font-weight:  700;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow8_col0 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow8_col1 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow8_col2 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow8_col3 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow8_col4 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow8_col5 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow8_col6 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow8_col7 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow8_col8 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow8_col9 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow8_col10 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow9_col0 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow9_col1 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow9_col2 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow9_col3 {\n",
       "            color:  red;\n",
       "            font-weight:  700;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow9_col4 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow9_col5 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow9_col6 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow9_col7 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow9_col8 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow9_col9 {\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }    #T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow9_col10 {\n",
       "            color:  red;\n",
       "            font-weight:  700;\n",
       "        }</style>  \n",
       "<table id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9e\" > \n",
       "<thead>    <tr> \n",
       "        <th class=\"blank level0\" ></th> \n",
       "        <th class=\"col_heading level0 col0\" >Topic0</th> \n",
       "        <th class=\"col_heading level0 col1\" >Topic1</th> \n",
       "        <th class=\"col_heading level0 col2\" >Topic2</th> \n",
       "        <th class=\"col_heading level0 col3\" >Topic3</th> \n",
       "        <th class=\"col_heading level0 col4\" >Topic4</th> \n",
       "        <th class=\"col_heading level0 col5\" >Topic5</th> \n",
       "        <th class=\"col_heading level0 col6\" >Topic6</th> \n",
       "        <th class=\"col_heading level0 col7\" >Topic7</th> \n",
       "        <th class=\"col_heading level0 col8\" >Topic8</th> \n",
       "        <th class=\"col_heading level0 col9\" >Topic9</th> \n",
       "        <th class=\"col_heading level0 col10\" >dominant_topic</th> \n",
       "    </tr></thead> \n",
       "<tbody>    <tr> \n",
       "        <th id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9elevel0_row0\" class=\"row_heading level0 row0\" >Doc0</th> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow0_col0\" class=\"data row0 col0\" >0.05</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow0_col1\" class=\"data row0 col1\" >0.05</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow0_col2\" class=\"data row0 col2\" >0.05</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow0_col3\" class=\"data row0 col3\" >0.05</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow0_col4\" class=\"data row0 col4\" >0.05</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow0_col5\" class=\"data row0 col5\" >0.55</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow0_col6\" class=\"data row0 col6\" >0.05</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow0_col7\" class=\"data row0 col7\" >0.05</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow0_col8\" class=\"data row0 col8\" >0.05</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow0_col9\" class=\"data row0 col9\" >0.05</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow0_col10\" class=\"data row0 col10\" >5</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9elevel0_row1\" class=\"row_heading level0 row1\" >Doc1</th> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow1_col0\" class=\"data row1 col0\" >0.1</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow1_col1\" class=\"data row1 col1\" >0.1</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow1_col2\" class=\"data row1 col2\" >0.1</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow1_col3\" class=\"data row1 col3\" >0.1</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow1_col4\" class=\"data row1 col4\" >0.1</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow1_col5\" class=\"data row1 col5\" >0.1</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow1_col6\" class=\"data row1 col6\" >0.1</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow1_col7\" class=\"data row1 col7\" >0.1</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow1_col8\" class=\"data row1 col8\" >0.1</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow1_col9\" class=\"data row1 col9\" >0.1</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow1_col10\" class=\"data row1 col10\" >0</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9elevel0_row2\" class=\"row_heading level0 row2\" >Doc2</th> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow2_col0\" class=\"data row2 col0\" >0.1</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow2_col1\" class=\"data row2 col1\" >0.1</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow2_col2\" class=\"data row2 col2\" >0.1</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow2_col3\" class=\"data row2 col3\" >0.1</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow2_col4\" class=\"data row2 col4\" >0.1</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow2_col5\" class=\"data row2 col5\" >0.1</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow2_col6\" class=\"data row2 col6\" >0.1</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow2_col7\" class=\"data row2 col7\" >0.1</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow2_col8\" class=\"data row2 col8\" >0.1</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow2_col9\" class=\"data row2 col9\" >0.1</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow2_col10\" class=\"data row2 col10\" >0</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9elevel0_row3\" class=\"row_heading level0 row3\" >Doc3</th> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow3_col0\" class=\"data row3 col0\" >0.05</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow3_col1\" class=\"data row3 col1\" >0.05</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow3_col2\" class=\"data row3 col2\" >0.05</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow3_col3\" class=\"data row3 col3\" >0.05</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow3_col4\" class=\"data row3 col4\" >0.55</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow3_col5\" class=\"data row3 col5\" >0.05</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow3_col6\" class=\"data row3 col6\" >0.05</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow3_col7\" class=\"data row3 col7\" >0.05</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow3_col8\" class=\"data row3 col8\" >0.05</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow3_col9\" class=\"data row3 col9\" >0.05</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow3_col10\" class=\"data row3 col10\" >4</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9elevel0_row4\" class=\"row_heading level0 row4\" >Doc4</th> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow4_col0\" class=\"data row4 col0\" >0.02</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow4_col1\" class=\"data row4 col1\" >0.02</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow4_col2\" class=\"data row4 col2\" >0.44</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow4_col3\" class=\"data row4 col3\" >0.02</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow4_col4\" class=\"data row4 col4\" >0.42</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow4_col5\" class=\"data row4 col5\" >0.02</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow4_col6\" class=\"data row4 col6\" >0.02</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow4_col7\" class=\"data row4 col7\" >0.02</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow4_col8\" class=\"data row4 col8\" >0.02</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow4_col9\" class=\"data row4 col9\" >0.02</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow4_col10\" class=\"data row4 col10\" >2</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9elevel0_row5\" class=\"row_heading level0 row5\" >Doc5</th> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow5_col0\" class=\"data row5 col0\" >0.03</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow5_col1\" class=\"data row5 col1\" >0.27</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow5_col2\" class=\"data row5 col2\" >0.03</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow5_col3\" class=\"data row5 col3\" >0.03</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow5_col4\" class=\"data row5 col4\" >0.03</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow5_col5\" class=\"data row5 col5\" >0.03</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow5_col6\" class=\"data row5 col6\" >0.03</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow5_col7\" class=\"data row5 col7\" >0.27</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow5_col8\" class=\"data row5 col8\" >0.03</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow5_col9\" class=\"data row5 col9\" >0.28</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow5_col10\" class=\"data row5 col10\" >9</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9elevel0_row6\" class=\"row_heading level0 row6\" >Doc6</th> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow6_col0\" class=\"data row6 col0\" >0.01</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow6_col1\" class=\"data row6 col1\" >0.01</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow6_col2\" class=\"data row6 col2\" >0.01</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow6_col3\" class=\"data row6 col3\" >0.01</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow6_col4\" class=\"data row6 col4\" >0.01</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow6_col5\" class=\"data row6 col5\" >0.01</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow6_col6\" class=\"data row6 col6\" >0.89</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow6_col7\" class=\"data row6 col7\" >0.01</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow6_col8\" class=\"data row6 col8\" >0.01</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow6_col9\" class=\"data row6 col9\" >0.01</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow6_col10\" class=\"data row6 col10\" >6</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9elevel0_row7\" class=\"row_heading level0 row7\" >Doc7</th> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow7_col0\" class=\"data row7 col0\" >0.03</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow7_col1\" class=\"data row7 col1\" >0.03</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow7_col2\" class=\"data row7 col2\" >0.77</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow7_col3\" class=\"data row7 col3\" >0.03</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow7_col4\" class=\"data row7 col4\" >0.03</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow7_col5\" class=\"data row7 col5\" >0.03</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow7_col6\" class=\"data row7 col6\" >0.03</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow7_col7\" class=\"data row7 col7\" >0.03</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow7_col8\" class=\"data row7 col8\" >0.03</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow7_col9\" class=\"data row7 col9\" >0.03</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow7_col10\" class=\"data row7 col10\" >2</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9elevel0_row8\" class=\"row_heading level0 row8\" >Doc8</th> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow8_col0\" class=\"data row8 col0\" >0.1</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow8_col1\" class=\"data row8 col1\" >0.1</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow8_col2\" class=\"data row8 col2\" >0.1</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow8_col3\" class=\"data row8 col3\" >0.1</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow8_col4\" class=\"data row8 col4\" >0.1</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow8_col5\" class=\"data row8 col5\" >0.1</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow8_col6\" class=\"data row8 col6\" >0.1</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow8_col7\" class=\"data row8 col7\" >0.1</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow8_col8\" class=\"data row8 col8\" >0.1</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow8_col9\" class=\"data row8 col9\" >0.1</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow8_col10\" class=\"data row8 col10\" >0</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9elevel0_row9\" class=\"row_heading level0 row9\" >Doc9</th> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow9_col0\" class=\"data row9 col0\" >0.05</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow9_col1\" class=\"data row9 col1\" >0.05</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow9_col2\" class=\"data row9 col2\" >0.05</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow9_col3\" class=\"data row9 col3\" >0.55</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow9_col4\" class=\"data row9 col4\" >0.05</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow9_col5\" class=\"data row9 col5\" >0.05</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow9_col6\" class=\"data row9 col6\" >0.05</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow9_col7\" class=\"data row9 col7\" >0.05</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow9_col8\" class=\"data row9 col8\" >0.05</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow9_col9\" class=\"data row9 col9\" >0.05</td> \n",
       "        <td id=\"T_67f44dbe_aff5_11e9_a8e1_e1f555edcb9erow9_col10\" class=\"data row9 col10\" >3</td> \n",
       "    </tr></tbody> \n",
       "</table> "
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2179415a748>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Document - Topic Matrix\n",
    "lda_output = best_lda_model.transform(lda_data_vectorized)\n",
    "# column names\n",
    "topicnames = [\"Topic\" + str(i) for i in range(0, 10)]\n",
    "\n",
    "# index names\n",
    "docnames = [\"Doc\" + str(i) for i in range(len(df.output))]\n",
    "\n",
    "# Make the pandas dataframe\n",
    "df_document_topic = pd.DataFrame(np.round(lda_output, 2), columns=topicnames, index=docnames)\n",
    "\n",
    "# Get dominant topic for each document\n",
    "dominant_topic = np.argmax(df_document_topic.values, axis=1)\n",
    "df_document_topic['dominant_topic'] = dominant_topic\n",
    "\n",
    "# Styling\n",
    "def color_red(val):\n",
    "    color = 'red' if val > .1 else 'black'\n",
    "    return 'color: {col}'.format(col=color)\n",
    "\n",
    "def make_bold(val):\n",
    "    weight = 700 if val > .1 else 400\n",
    "    return 'font-weight: {weight}'.format(weight=weight)\n",
    "\n",
    "# Apply Style\n",
    "df_document_topics = df_document_topic.head(10).style.applymap(color_red).applymap(make_bold)\n",
    "df_document_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dominant_topic</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dominant_topic</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                dominant_topic\n",
       "dominant_topic                \n",
       "0                         5863\n",
       "1                         1046\n",
       "2                          644\n",
       "3                          611\n",
       "4                          728\n",
       "5                         1049\n",
       "6                          787\n",
       "7                          780\n",
       "8                          842\n",
       "9                          672"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_document_topic.groupby('dominant_topic')[['dominant_topic']].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GridSearch from sklearn using cross validation option advised to have 10 topic, but using human judgment I consider too many documents assighed per each topic (more than 1000 few topics). \n",
    "\n",
    "Additionally, I tried *doc2vec* but performance was poor I did not include it in the script (I predict it is due to limited vocabulary). Maybe if run it on full article text it will be more sensible.\n",
    "\n",
    "Conclusion: the LDA has good potential and with realisation provided as first solution above and gives exciting result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2. Extract information about breaking news events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have identified which articles are linked to their respective events, please attempt to derive meaningful information about these events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gest the data need for this question\n",
    "df_q2 = pd.concat([df, df_q1.EventId], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Article Subject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Spacy to extract Named Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.gold import GoldParse \n",
    "  \n",
    "nlp = spacy.load('en', entity = False, parser = False) \n",
    "entities = ['PERSON', 'GPE']\n",
    "\n",
    "#df_q2['GoldParse'] = df.output_ne.apply(lambda x: GoldParse(nlp.make_doc(x), entities).orig_annot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I extract most common city, country, person name from the articles to get the subject of the event. \n",
    "I did not split country city and person into two columns as there are articles where no location mentioned and I do not want to have an empty field in the ArticleSubject column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EventId\n",
       "0.0       Tony West Taiwan Jakarta\n",
       "1.0            Dundee McIntyre Jim\n",
       "2.0            Dineo Solo Moeketsi\n",
       "3.0                         Penang\n",
       "4.0                       Dry Mark\n",
       "5.0                 Yusran Maulana\n",
       "6.0    Kent Essex MacGregor Tartan\n",
       "7.0                 Bielsa Marcelo\n",
       "8.0                 Tillie Killian\n",
       "9.0                   Oakland Port\n",
       "Name: ArticleSubject, dtype: object"
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract country, city, person name most probable in the articles per event\n",
    "df_q2['ArticleSubject'] = df.ne_span.apply(lambda x: ' '.join(item for item in set([ent.text for ent in x.ents \n",
    "                                                                 if ent.label_ in entities])))\n",
    "df_sum = pd.DataFrame(df_q2[df_q2.EventId > -1].groupby('EventId')['ArticleSubject'].apply(lambda x: \n",
    "                                                                                       Counter([item for item in x if len(item)>0])\n",
    "                                                                                       .most_common()[:-1-1:-1][0][0]  ))\n",
    "df_sum.ArticleSubject = df_sum.ArticleSubject.apply(lambda x: ' '.join([item[0] for item in Counter(tokenize(str(x))).most_common(4)[:-4-1:-1]]))\n",
    "df_sum.ArticleSubject.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Article Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleSubject</th>\n",
       "      <th>ArticleTime</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EventId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>Tony West Taiwan Jakarta</td>\n",
       "      <td>1557660519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>Dundee McIntyre Jim</td>\n",
       "      <td>1557661019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>Dineo Solo Moeketsi</td>\n",
       "      <td>1557656777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ArticleSubject  ArticleTime\n",
       "EventId                                       \n",
       "0.0      Tony West Taiwan Jakarta   1557660519\n",
       "1.0           Dundee McIntyre Jim   1557661019\n",
       "2.0           Dineo Solo Moeketsi   1557656777"
      ]
     },
     "execution_count": 580,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp = df_q2[df_q2.EventId > -1].sort_values(['EventId', 'ArticlePublishedTime'], ascending = [True, True]).drop_duplicates('EventId', keep='first')['ArticlePublishedTime']\n",
    "df_sum['ArticleTime'] = list(df_temp)\n",
    "df_sum[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Article summary through page rank algorithm and cosine similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will extract most relevant sentence within all data given per event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PageRank(M, eps = 1.0e-08, d = 0.85):\n",
    "    N = M.shape[1]\n",
    "    v = np.random.rand(N, 1)\n",
    "    v = v/ np.linalg.norm(v, 1)\n",
    "    last_v = np.ones((N, 1), dtype = np.float32)*np.inf\n",
    "    M_hat = (d*M)+(((1-d)/N)*np.ones((N,N), dtype = np.float32))\n",
    "    \n",
    "    while np.linalg.norm(v - last_v, 2) > eps:\n",
    "        last_v = v\n",
    "        v = np.matmul(M_hat, v)\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(sent1, sent2):\n",
    "    vocab = list(set(sent1 + sent2))\n",
    "    vector1 = [0]*len(vocab)\n",
    "    vector2 = [0]*len(vocab)\n",
    "    \n",
    "    for  word in sent1:\n",
    "        vector1[vocab.index(word)] +=1\n",
    "    \n",
    "    for  word in sent2:\n",
    "        vector2[vocab.index(word)] +=1\n",
    "    \n",
    "    return 1 - cosine_distance(vector1, vector2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_matrix(sentences):\n",
    "    S = np.zeros((len(sentences), len(sentences)))\n",
    "    for i in range(len(sentences)):\n",
    "        for j in range(len(sentences)):\n",
    "            if i == j:\n",
    "                continue\n",
    "            else:\n",
    "                S[i][j] = cos_sim(sentences[i], sentences[j])\n",
    "                \n",
    "    for i in range(len(S)):\n",
    "        S[i] /= S[i].sum()\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_q1['_Article'] = df_q1.ArticleTitle + ' ' + df_q2.ArticleDescription\n",
    "\n",
    "#I want to extract one sentence as a summary\n",
    "SUMMARY_SIZE = 1\n",
    "final_summary = []\n",
    "\n",
    "#run over all 100 topic\n",
    "for i in range(0, 100):\n",
    "    df_temp = df_q1[df_q1.EventId == i]\n",
    "    # save all article in a list\n",
    "    documents = list(*[df_temp[c].values.tolist() for c in ['_Article']])\n",
    "    S = similarity_matrix(documents)\n",
    "    #find sentences ranks within every event\n",
    "    sentence_rank = PageRank(S)\n",
    "    #find sentence index\n",
    "    sentence_index = [item[0] for item in sorted(enumerate(sentence_rank), key = lambda item: -item[1])]\n",
    "    article_sum = itemgetter(*sorted(article_index[:SUMMARY_SIZE]))(documents)\n",
    "    final_summary.append(article_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add summary into final output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sum['ArticleMain'] = final_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleSubject</th>\n",
       "      <th>ArticleTime</th>\n",
       "      <th>ArticleMain</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EventId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>Tony West Taiwan Jakarta</td>\n",
       "      <td>1557660519</td>\n",
       "      <td>Aussie parties turn to WeChat to woo Chinese C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>Dundee McIntyre Jim</td>\n",
       "      <td>1557661019</td>\n",
       "      <td>Dundee manager Jim McIntyre leaves post Dundee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>Dineo Solo Moeketsi</td>\n",
       "      <td>1557656777</td>\n",
       "      <td>Climb inside Oakland Airport's massive new fir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>Penang</td>\n",
       "      <td>1557658811</td>\n",
       "      <td>Why borrowing makes sense as a financial strat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>Dry Mark</td>\n",
       "      <td>1557662413</td>\n",
       "      <td>Should Rangers ace Jon Flanagan have been sent...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ArticleSubject  ArticleTime  \\\n",
       "EventId                                          \n",
       "0.0      Tony West Taiwan Jakarta   1557660519   \n",
       "1.0           Dundee McIntyre Jim   1557661019   \n",
       "2.0           Dineo Solo Moeketsi   1557656777   \n",
       "3.0                        Penang   1557658811   \n",
       "4.0                      Dry Mark   1557662413   \n",
       "\n",
       "                                               ArticleMain  \n",
       "EventId                                                     \n",
       "0.0      Aussie parties turn to WeChat to woo Chinese C...  \n",
       "1.0      Dundee manager Jim McIntyre leaves post Dundee...  \n",
       "2.0      Climb inside Oakland Airport's massive new fir...  \n",
       "3.0      Why borrowing makes sense as a financial strat...  \n",
       "4.0      Should Rangers ace Jon Flanagan have been sent...  "
      ]
     },
     "execution_count": 654,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sum.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have not implemented pre-processing at this question due to run out of time. With a sentence pre-processing the performance will be better. This pre-processing not the same as done for the question one. \n",
    "\n",
    "**Conclusion**\n",
    "\n",
    "As a summary I picked the most relevant sentence within all articles (among article titles and descriptions) per event. I realize that this is not a summary but main idea. However, in general it can be suitable in some point when we need to make a short description for example.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
